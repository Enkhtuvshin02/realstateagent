
import logging
import json
import re
from datetime import datetime
from pathlib import Path
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

logger = logging.getLogger(__name__)


class ReportService:
    def __init__(self, llm, district_analyzer, pdf_generator, search_tool=None):
        self.llm = llm
        self.district_analyzer = district_analyzer
        self.pdf_generator = pdf_generator
        self.search_tool = search_tool

    async def generate_property_report(self, analysis_data: dict) -> str:
        """Generate property analysis PDF report with search integration"""
        logger.info("üìÑ Generating property report with search integration")

        try:
            # Check if analysis is recent (within last 10 minutes)
            analysis_time = datetime.fromisoformat(analysis_data["timestamp"])
            time_diff = datetime.now() - analysis_time

            if time_diff.total_seconds() > 600:  # 10 minutes
                return {
                    "message": "–û—Ä–æ–Ω —Å—É—É—Ü–Ω—ã —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö—É—É—á–∏—Ä—Å–∞–Ω –±–∞–π–Ω–∞. –≠—Ö–ª—ç—ç–¥ –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã —Ö–æ–ª–±–æ–æ—Å—ã–≥ –∏–ª–≥—ç—ç–≥—ç—ç–¥ –¥–∞—Ä–∞–∞ –Ω—å —Ç–∞–π–ª–∞–Ω —Ö“Ø—Å—ç—Ö –±–æ–ª–æ–º–∂—Ç–æ–π.",
                    "success": False
                }

            # Perform internet search for market research
            search_results = ""
            if self.search_tool:
                try:
                    district_name = analysis_data["property_details"].get("district", "")
                    search_query = f"–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä {district_name} –¥“Ø“Ø—Ä—ç–≥ –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª “Ø–Ω—ç 2024 2025"
                    logger.info(f"üîç Searching for: {search_query}")

                    search_response = self.search_tool.invoke({"query": search_query})
                    if search_response:
                        search_results = await self._process_search_results(search_response, "property")
                        logger.info("‚úÖ Search results processed for property report")
                except Exception as e:
                    logger.error(f"‚ùå Search failed: {e}")
                    search_results = "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç —Ö–∏–π—Ö—ç–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞."

            # Generate detailed analysis for PDF in Mongolian
            detailed_analysis = await self._generate_detailed_property_analysis_mn(
                analysis_data["property_details"],
                analysis_data["district_analysis"]
            )

            # Generate PDF with search results
            pdf_path = self.pdf_generator.generate_property_analysis_report(
                property_data=analysis_data["property_details"],
                district_analysis=analysis_data["district_analysis"],
                comparison_result=detailed_analysis,
                search_results=search_results
            )

            filename = Path(pdf_path).name
            download_url = f"/download-report/{filename}"

            return {
                "message": f"‚úÖ –û—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π PDF —Ç–∞–π–ª–∞–Ω –∞–º–∂–∏–ª—Ç—Ç–∞–π “Ø“Ø—Å–≥—ç–≥–¥–ª—ç—ç!",
                "filename": filename,
                "download_url": download_url,
                "success": True
            }

        except Exception as e:
            logger.error(f"‚ùå Error generating property report: {e}")
            return {
                "message": f"–¢–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö—ç–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {str(e)}. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.",
                "success": False
            }

    async def generate_district_report(self) -> str:
        """Generate district comparison PDF report with search integration"""
        logger.info("üìä Generating district report with search integration")

        try:
            # Ensure fresh data
            await self.district_analyzer.ensure_fresh_data()

            # Extract district data
            districts_data = self._extract_districts_data()

            if not districts_data:
                return "–î“Ø“Ø—Ä–≥–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É."

            # Perform internet search for market trends
            search_results = ""
            if self.search_tool:
                try:
                    search_query = "–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª “Ø–Ω—ç —á–∏–≥–ª—ç–ª 2024 2025 –¥“Ø“Ø—Ä—ç–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç"
                    logger.info(f"üîç Searching for market trends: {search_query}")

                    search_response = self.search_tool.invoke({"query": search_query})
                    if search_response:
                        search_results = await self._process_search_results(search_response, "market")
                        logger.info("‚úÖ Search results processed for district report")
                except Exception as e:
                    logger.error(f"‚ùå Search failed: {e}")
                    search_results = "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç —Ö–∏–π—Ö—ç–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞."

            # Generate market trends analysis in Mongolian
            market_trends = await self._generate_market_trends_analysis_mn(districts_data)

            # Generate PDF with search results
            pdf_path = self.pdf_generator.generate_district_summary_report(
                districts_data=districts_data,
                market_trends=market_trends,
                search_results=search_results
            )

            filename = Path(pdf_path).name
            download_url = f"/download-report/{filename}"

            return {
                "message": f"‚úÖ –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –¥“Ø“Ø—Ä–≥–∏–π–Ω —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç—ã–Ω PDF —Ç–∞–π–ª–∞–Ω –∞–º–∂–∏–ª—Ç—Ç–∞–π “Ø“Ø—Å–≥—ç–≥–¥–ª—ç—ç!",
                "filename": filename,
                "download_url": download_url,
                "success": True
            }

        except Exception as e:
            logger.error(f"‚ùå Error generating district report: {e}")
            return {
                "message": f"–¢–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö—ç–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {str(e)}. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.",
                "success": False
            }

    async def _process_search_results(self, search_response, report_type: str) -> str:
        """Process search results and generate relevant summary in Mongolian"""
        try:
            # Extract useful information from search results
            search_text = ""
            if isinstance(search_response, list):
                for result in search_response:
                    if isinstance(result, dict):
                        content = result.get('content', '') or result.get('snippet', '')
                        title = result.get('title', '')
                        if content:
                            search_text += f"{title}: {content}\n"
                    else:
                        search_text += str(result) + "\n"
            else:
                search_text = str(search_response)

            if not search_text.strip():
                return "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç–∞–∞—Å –º—ç–¥—ç—ç–ª—ç–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π."

            # Generate summary based on report type
            if report_type == "property":
                prompt = ChatPromptTemplate.from_messages([
                    ("system",
                     "–¢–∞ –±–æ–ª “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω —à–∏–Ω–∂—ç—ç—á. –ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥—ç—ç—Å –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —á—É—Ö–∞–ª –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –Ω—ç–≥—Ç–≥—ç–Ω —Ö–∞—Ä—É—É–ª–Ω–∞ —É—É. –ó”©–≤—Ö”©–Ω —Ö–∞–º–≥–∏–π–Ω —á—É—Ö–∞–ª –º—ç–¥—ç—ç–ª–ª–∏–π–≥ —Ç–æ–≤—á —Ç–æ–¥–æ—Ä—Ö–æ–π –±–∞–π–¥–ª–∞–∞—Ä –±–∏—á–Ω—ç “Ø“Ø."),
                    ("human",
                     "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω: {search_results}\n\n–û—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —Ç–∞–ª–∞–∞—Ä—Ö —á—É—Ö–∞–ª –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –Ω—ç–≥—Ç–≥—ç–Ω —Ö–∞—Ä—É—É–ª–Ω–∞ —É—É.")
                ])
            else:  # market trends
                prompt = ChatPromptTemplate.from_messages([
                    ("system",
                     "–¢–∞ –±–æ–ª “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —à–∏–Ω–∂—ç—ç—á. –ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥—ç—ç—Å –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –µ—Ä”©–Ω—Ö–∏–π —á–∏–≥ —Ö–∞–Ω–¥–ª–∞–≥—ã–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –Ω—ç–≥—Ç–≥—ç–Ω —Ö–∞—Ä—É—É–ª–Ω–∞ —É—É."),
                    ("human",
                     "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω: {search_results}\n\n–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —á–∏–≥ —Ö–∞–Ω–¥–ª–∞–≥—ã–Ω —Ç–∞–ª–∞–∞—Ä—Ö –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä –Ω—ç–≥—Ç–≥—ç–Ω —Ö–∞—Ä—É—É–ª–Ω–∞ —É—É.")
                ])

            chain = prompt | self.llm | StrOutputParser()
            summary = await chain.ainvoke({"search_results": search_text[:3000]})  # Limit text length

            return summary if summary else "–•–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥—ç—ç—Å –º—ç–¥—ç—ç–ª—ç–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π."

        except Exception as e:
            logger.error(f"‚ùå Error processing search results: {e}")
            return "–•–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥ –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞."

    async def _generate_detailed_property_analysis_mn(self, property_details: dict, district_analysis: str) -> str:
        """Generate detailed property analysis in Mongolian"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢–∞ –±–æ–ª “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω. –û—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —à–∏–Ω–∂–∏–ª–≥—ç—ç–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∏–π–Ω—ç “Ø“Ø. 

–î–∞—Ä–∞–∞—Ö –∑“Ø–π–ª—Å–∏–π–≥ –∞–≥—É—É–ª–Ω–∞ —É—É:
1. –ó–∞—Ö –∑—ç—ç–ª –¥—ç—Ö –±–∞–π—Ä —Å—É—É—Ä—å
2. –•”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–ª—Ç—ã–Ω –±–æ–ª–æ–º–∂
3. –î“Ø“Ø—Ä–≥–∏–π–Ω –¥—É–Ω–¥–∞–∂—Ç–∞–π —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç  
4. –≠—Ä—Å–¥–ª–∏–π–Ω “Ø–Ω—ç–ª–≥—ç—ç
5. –ó”©–≤–ª”©–º–∂“Ø“Ø–¥

–ó”©–≤—Ö”©–Ω –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä, —Ç–æ–¥–æ—Ä—Ö–æ–π, –ø—Ä–∞–∫—Ç–∏–∫ –∑”©–≤–ª”©–º–∂ ”©–≥–Ω”© “Ø“Ø."""),
            ("human", """–û—Ä–æ–Ω —Å—É—É—Ü: {property_details}
–î“Ø“Ø—Ä–≥–∏–π–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç: {district_analysis}

–≠–Ω—ç –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∏–π–Ω—ç “Ø“Ø.""")
        ])

        chain = prompt | self.llm | StrOutputParser()
        analysis = await chain.ainvoke({
            "property_details": json.dumps(property_details, ensure_ascii=False, indent=2),
            "district_analysis": district_analysis
        })

        return analysis

    async def _generate_market_trends_analysis_mn(self, districts_data: list) -> str:
        """Generate market trends analysis in Mongolian"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢–∞ –±–æ–ª “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —à–∏–Ω–∂—ç—ç—á. –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –¥“Ø“Ø—Ä–≥“Ø“Ø–¥–∏–π–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∏–π–Ω—ç “Ø“Ø.

–î–∞—Ä–∞–∞—Ö –∑“Ø–π–ª—Å–∏–π–≥ –∞–≥—É—É–ª–Ω–∞ —É—É:
1. –ï—Ä”©–Ω—Ö–∏–π –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –Ω”©—Ö—Ü”©–ª –±–∞–π–¥–∞–ª
2. –î“Ø“Ø—Ä—ç–≥ —Ö–æ–æ—Ä–æ–Ω–¥—ã–Ω “Ø–Ω–∏–π–Ω —è–ª–≥–∞–∞
3. –•”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–ª—Ç—ã–Ω –±–æ–ª–æ–º–∂—É—É–¥
4. –ó–∞—Ö –∑—ç—ç–ª–∏–π–Ω ”©—Å”©–ª—Ç–∏–π–Ω —á–∏–≥–ª—ç–ª
5. ”®”©—Ä ”©”©—Ä —Ö—É–¥–∞–ª–¥–∞–Ω –∞–≤–∞–≥—á–¥–∞–¥ –∑–æ—Ä–∏—É–ª—Å–∞–Ω –∑”©–≤–ª”©–º–∂

–ó”©–≤—Ö”©–Ω –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä, –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö–∏–π–Ω—ç “Ø“Ø."""),
            ("human", """–î“Ø“Ø—Ä–≥“Ø“Ø–¥–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª: {districts_data}

–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —á–∏–≥ —Ö–∞–Ω–¥–ª–∞–≥—ã–≥ —ç–Ω—ç –º—ç–¥—ç—ç–ª—ç–ª–¥ “Ø–Ω–¥—ç—Å–ª—ç–Ω –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —à–∏–Ω–∂–∏–ª–Ω—ç “Ø“Ø.""")
        ])

        chain = prompt | self.llm | StrOutputParser()
        analysis = await chain.ainvoke({
            "districts_data": json.dumps(districts_data, ensure_ascii=False, indent=2)
        })

        return analysis

    def _extract_districts_data(self) -> list:
        """Extract district data from vectorstore with improved parsing"""
        if not self.district_analyzer.vectorstore:
            logger.warning("No vectorstore available")
            return []

        available_docs = list(self.district_analyzer.vectorstore.docstore._dict.values())
        districts_data = []

        logger.info(f"Extracting data from {len(available_docs)} documents...")

        for doc in available_docs:
            lines = doc.page_content.strip().split('\n')
            district_info = {}

            logger.debug(f"Processing document with content: {doc.page_content[:100]}...")

            for line in lines:
                line = line.strip()

                # Extract district name
                if '–î“Ø“Ø—Ä—ç–≥:' in line:
                    district_info['name'] = line.replace('–î“Ø“Ø—Ä—ç–≥:', '').strip()
                    logger.debug(f"Found district: {district_info['name']}")

                # Extract overall average price
                elif '–ù–∏–π—Ç –±–∞–π—Ä–Ω—ã 1–º2 –¥—É–Ω–¥–∞–∂ “Ø–Ω—ç:' in line:
                    price_match = re.search(r'(\d[\d\s,]*)', line)
                    if price_match:
                        price_str = price_match.group(1).replace(' ', '').replace(',', '')
                        try:
                            district_info['overall_avg'] = float(price_str)
                            logger.debug(f"Extracted overall avg: {district_info['overall_avg']}")
                        except ValueError as e:
                            logger.warning(f"Could not parse overall price '{price_str}': {e}")
                            district_info['overall_avg'] = 0

                # Extract 2-room price
                elif '2 ”©—Ä”©”© –±–∞–π—Ä–Ω—ã 1–º2 –¥—É–Ω–¥–∞–∂ “Ø–Ω—ç:' in line:
                    price_match = re.search(r'(\d[\d\s,]*)', line)
                    if price_match:
                        price_str = price_match.group(1).replace(' ', '').replace(',', '')
                        try:
                            district_info['two_room_avg'] = float(price_str)
                            logger.debug(f"Extracted 2-room avg: {district_info['two_room_avg']}")
                        except ValueError as e:
                            logger.warning(f"Could not parse 2-room price '{price_str}': {e}")
                            district_info['two_room_avg'] = 0

                # Extract 3-room price
                elif '3 ”©—Ä”©”© –±–∞–π—Ä–Ω—ã 1–º2 –¥—É–Ω–¥–∞–∂ “Ø–Ω—ç:' in line:
                    price_match = re.search(r'(\d[\d\s,]*)', line)
                    if price_match:
                        price_str = price_match.group(1).replace(' ', '').replace(',', '')
                        try:
                            district_info['three_room_avg'] = float(price_str)
                            logger.debug(f"Extracted 3-room avg: {district_info['three_room_avg']}")
                        except ValueError as e:
                            logger.warning(f"Could not parse 3-room price '{price_str}': {e}")
                            district_info['three_room_avg'] = 0

            # Only add district if we have a name and at least one price
            if district_info.get('name') and district_info.get('overall_avg', 0) > 0:
                districts_data.append(district_info)
                logger.info(f"Added district: {district_info['name']} with price {district_info['overall_avg']:,.0f}")
            else:
                logger.warning(f"Skipping incomplete district data: {district_info}")

        logger.info(f"Successfully extracted {len(districts_data)} districts with valid data")

        # If no valid data extracted, return fallback data
        if not districts_data:
            logger.warning("No valid district data found, using fallback data")
            districts_data = [
                {
                    'name': '–°“Ø—Ö–±–∞–∞—Ç–∞—Ä',
                    'overall_avg': 4500000,
                    'two_room_avg': 4600000,
                    'three_room_avg': 4400000
                },
                {
                    'name': '–•–∞–Ω-–£—É–ª',
                    'overall_avg': 4000323,
                    'two_room_avg': 4100323,
                    'three_room_avg': 3900323
                },
                {
                    'name': '–ß–∏–Ω–≥—ç–ª—Ç—ç–π',
                    'overall_avg': 3800000,
                    'two_room_avg': 3900000,
                    'three_room_avg': 3700000
                },
                {
                    'name': '–ë–∞—è–Ω–≥–æ–ª',
                    'overall_avg': 3510645,
                    'two_room_avg': 3610645,
                    'three_room_avg': 3410645
                },
                {
                    'name': '–ë–∞—è–Ω–∑“Ø—Ä—Ö',
                    'overall_avg': 3200000,
                    'two_room_avg': 3300000,
                    'three_room_avg': 3100000
                },
                {
                    'name': '–°–æ–Ω–≥–∏–Ω–æ—Ö–∞–π—Ä—Ö–∞–Ω',
                    'overall_avg': 2800000,
                    'two_room_avg': 2900000,
                    'three_room_avg': 2700000
                },
                {
                    'name': '–ë–∞–≥–∞–Ω—É—É—Ä',
                    'overall_avg': 2200000,
                    'two_room_avg': 2300000,
                    'three_room_avg': 2100000
                },
                {
                    'name': '–ù–∞–ª–∞–π—Ö',
                    'overall_avg': 2000000,
                    'two_room_avg': 2100000,
                    'three_room_avg': 1900000
                }
            ]

        return districts_data
    async def generate_comprehensive_market_report(self) -> str:
        """Generate a comprehensive market analysis report"""
        logger.info("üìà Generating comprehensive market report")

        try:
            # Ensure fresh data
            await self.district_analyzer.ensure_fresh_data()

            # Extract district data
            districts_data = self._extract_districts_data()

            if not districts_data:
                return "–î“Ø“Ø—Ä–≥–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É."

            # Perform multiple searches for comprehensive analysis
            search_results = ""
            if self.search_tool:
                try:
                    search_queries = [
                        "–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª 2024 2025 —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫",
                        "–ú–æ–Ω–≥–æ–ª –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã “Ø–Ω—ç ”©—Å”©–ª—Ç —á–∏–≥–ª—ç–ª",
                        "–£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —à–∏–Ω—ç —Ö–æ—Ä–æ–æ–ª–ª—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü",
                        "–ú–æ–Ω–≥–æ–ª “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω –∑—ç—ç–ª –∏–ø–æ—Ç–µ–∫"
                    ]

                    combined_results = []
                    for query in search_queries:
                        logger.info(f"üîç Searching: {query}")
                        try:
                            result = self.search_tool.invoke({"query": query})
                            if result:
                                combined_results.append(result)
                        except Exception as e:
                            logger.error(f"Search failed for '{query}': {e}")
                            continue

                    if combined_results:
                        search_results = await self._process_comprehensive_search_results(combined_results)
                        logger.info("‚úÖ Comprehensive search results processed")
                except Exception as e:
                    logger.error(f"‚ùå Comprehensive search failed: {e}")
                    search_results = "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç —Ö–∏–π—Ö—ç–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞."

            # Generate comprehensive market analysis
            market_analysis = await self._generate_comprehensive_market_analysis(districts_data, search_results)

            # Generate enhanced PDF
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"comprehensive_market_report_{timestamp}.pdf"

            # Use existing district report generator but with enhanced data
            pdf_path = self.pdf_generator.generate_district_summary_report(
                districts_data=districts_data,
                market_trends=market_analysis,
                search_results=search_results
            )

            filename = Path(pdf_path).name
            download_url = f"/download-report/{filename}"

            return {
                "message": f"‚úÖ –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —Ç–∞–π–ª–∞–Ω –∞–º–∂–∏–ª—Ç—Ç–∞–π “Ø“Ø—Å–≥—ç–≥–¥–ª—ç—ç!",
                "filename": filename,
                "download_url": download_url,
                "success": True
            }

        except Exception as e:
            logger.error(f"‚ùå Error generating comprehensive market report: {e}")
            return {
                "message": f"–î—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —Ç–∞–π–ª–∞–Ω “Ø“Ø—Å–≥—ç—Ö—ç–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞: {str(e)}. –î–∞—Ö–∏–Ω –æ—Ä–æ–ª–¥–æ–Ω–æ —É—É.",
                "success": False
            }

    async def _process_comprehensive_search_results(self, search_results_list) -> str:
        """Process multiple search results for comprehensive analysis"""
        try:
            all_content = ""
            for results in search_results_list:
                if isinstance(results, list):
                    for result in results:
                        if isinstance(result, dict):
                            content = result.get('content', '') or result.get('snippet', '')
                            title = result.get('title', '')
                            if content:
                                all_content += f"{title}: {content}\n"

            if not all_content.strip():
                return "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç–∞–∞—Å –º—ç–¥—ç—ç–ª—ç–ª –æ–ª–¥—Å–æ–Ω–≥“Ø–π."

            prompt = ChatPromptTemplate.from_messages([
                ("system", """–¢–∞ –±–æ–ª “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –º—ç—Ä–≥—ç–∂–∏–ª—Ç—ç–Ω. –û–ª–æ–Ω —Ö–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥—ç—ç—Å –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —à–∏–Ω–∂–∏–ª–≥—ç—ç–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∏–π–Ω—ç “Ø“Ø.

–î–∞—Ä–∞–∞—Ö –∑“Ø–π–ª—Å–∏–π–≥ —Ç—É—Å–≥–∞–Ω–∞ —É—É:
- –û–¥–æ–æ–≥–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –Ω”©—Ö—Ü”©–ª –±–∞–π–¥–∞–ª
- “Æ–Ω–∏–π–Ω –¥–∏–Ω–∞–º–∏–∫ –±–∞ —á–∏–≥–ª—ç–ª  
- –®–∏–Ω—ç —Ö”©–≥–∂–ª–∏–π–Ω —Ç”©—Å–ª“Ø“Ø–¥
- –°–∞–Ω—Ö“Ø“Ø–∂–∏–ª—Ç–∏–π–Ω –Ω”©—Ö—Ü”©–ª
- –ò—Ä—ç—ç–¥“Ø–π–Ω —Ç–∞–∞–º–∞–≥–ª–∞–ª

–ó”©–≤—Ö”©–Ω –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä, –º—ç—Ä–≥—ç–∂–ª–∏–π–Ω –¥“Ø–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö–∏–π–Ω—ç “Ø“Ø."""),
                ("human",
                 "–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Ö–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥“Ø“Ø–¥: {search_content}\n\n–≠–¥–≥—ç—ç—Ä –º—ç–¥—ç—ç–ª–ª—ç—ç—Å –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —à–∏–Ω–∂–∏–ª–≥—ç—ç–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∏–π–Ω—ç “Ø“Ø.")
            ])

            chain = prompt | self.llm | StrOutputParser()
            summary = await chain.ainvoke({"search_content": all_content[:4000]})  # Limit length

            return summary if summary else "–•–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥—ç—ç—Å –º—ç–¥—ç—ç–ª—ç–ª –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∂ —á–∞–¥—Å–∞–Ω–≥“Ø–π."

        except Exception as e:
            logger.error(f"‚ùå Error processing comprehensive search results: {e}")
            return "–•–∞–π–ª—Ç—ã–Ω “Ø—Ä –¥“Ø–Ω–≥ –±–æ–ª–æ–≤—Å—Ä—É—É–ª–∞—Ö–∞–¥ –∞–ª–¥–∞–∞ –≥–∞—Ä–ª–∞–∞."

    async def _generate_comprehensive_market_analysis(self, districts_data: list, search_results: str) -> str:
        """Generate comprehensive market analysis combining district data and search results"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """–¢–∞ –±–æ–ª “Ø–ª —Ö”©–¥–ª”©—Ö —Ö”©—Ä”©–Ω–≥–∏–π–Ω –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω —Ç—ç—Ä–≥“Ø“Ø–Ω–∏–π —à–∏–Ω–∂—ç—ç—á. –î“Ø“Ø—Ä–≥“Ø“Ø–¥–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª –±–æ–ª–æ–Ω –∏–Ω—Ç–µ—Ä–Ω—ç—Ç —Å—É–¥–∞–ª–≥–∞–∞–Ω—ã “Ø—Ä –¥“Ø–Ω–≥ —Ö–æ—Å–ª—É—É–ª–∞–Ω –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –∏–∂ –±“Ø—Ä—ç–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∏–π–Ω—ç “Ø“Ø.

–î–∞—Ä–∞–∞—Ö –±“Ø–ª–≥“Ø“Ø–¥–∏–π–≥ —Ç—É—Å–≥–∞–Ω–∞ —É—É:
1. –ó–∞—Ö –∑—ç—ç–ª–∏–π–Ω –µ—Ä”©–Ω—Ö–∏–π “Ø–Ω—ç–ª–≥—ç—ç
2. –î“Ø“Ø—Ä—ç–≥ —Ö–æ–æ—Ä–æ–Ω–¥—ã–Ω —Ö–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç  
3. “Æ–Ω–∏–π–Ω —á–∏–≥–ª—ç–ª –±–∞ —à–∞–ª—Ç–≥–∞–∞–Ω
4. –•”©—Ä”©–Ω–≥”© –æ—Ä—É—É–ª–∞–ª—Ç—ã–Ω –±–æ–ª–æ–º–∂—É—É–¥
5. –≠—Ä—Å–¥—ç–ª –±–∞ —Å–æ—Ä–∏–ª—Ç
6. –ò—Ä—ç—ç–¥“Ø–π–Ω —Ç”©–ª”©–≤

–ú—ç—Ä–≥—ç–∂–ª–∏–π–Ω, –¥—ç–ª–≥—ç—Ä—ç–Ω–≥“Ø–π —à–∏–Ω–∂–∏–ª–≥—ç—ç —Ö–∏–π–Ω—ç “Ø“Ø."""),
            ("human", """–î“Ø“Ø—Ä–≥“Ø“Ø–¥–∏–π–Ω –º—ç–¥—ç—ç–ª—ç–ª: {districts_data}

–ò–Ω—Ç–µ—Ä–Ω—ç—Ç —Å—É–¥–∞–ª–≥–∞–∞–Ω—ã “Ø—Ä –¥“Ø–Ω: {search_results}

–≠–¥–≥—ç—ç—Ä –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –Ω—ç–≥—Ç–≥—ç–Ω –£–ª–∞–∞–Ω–±–∞–∞—Ç–∞—Ä —Ö–æ—Ç—ã–Ω –æ—Ä–æ–Ω —Å—É—É—Ü–Ω—ã –∑–∞—Ö –∑—ç—ç–ª–∏–π–Ω –∏–∂ –±“Ø—Ä—ç–Ω —à–∏–Ω–∂–∏–ª–≥—ç—ç–≥ –ú–æ–Ω–≥–æ–ª —Ö—ç–ª—ç—ç—Ä —Ö–∏–π–Ω—ç “Ø“Ø.""")
        ])

        chain = prompt | self.llm | StrOutputParser()
        analysis = await chain.ainvoke({
            "districts_data": json.dumps(districts_data, ensure_ascii=False, indent=2),
            "search_results": search_results
        })

        return analysis


def _parse_price_from_text(self, text: str) -> float:
    """Parse price from Mongolian text with various formats"""
    if not text:
        return 0

    # Remove common Mongolian price indicators
    text = text.replace('—Ç”©–≥—Ä”©–≥', '').replace('‚ÇÆ', '').strip()

    # Handle million format
    if '—Å–∞—è' in text.lower():
        match = re.search(r'(\d+(?:[,.]\d+)?)', text)
        if match:
            try:
                number = float(match.group(1).replace(',', '.'))
                return number * 1_000_000
            except ValueError:
                pass

    # Handle billion format
    if '—Ç—ç—Ä–±—É–º' in text.lower():
        match = re.search(r'(\d+(?:[,.]\d+)?)', text)
        if match:
            try:
                number = float(match.group(1).replace(',', '.'))
                return number * 1_000_000_000
            except ValueError:
                pass

    # Handle direct number format (with spaces as thousands separators)
    text = text.replace(' ', '').replace(',', '')
    match = re.search(r'(\d+)', text)
    if match:
        try:
            return float(match.group(1))
        except ValueError:
            pass

    return 0